// time webppl priors-2.wppl --require mht --require habutils

var fpath = "/Users/mht/Documents/research/habituals/models/priors/data/"
var fpath2 = "/Users/mht/Documents/research/habituals/models/truthjudgement/data/"

var existData = mht.readCSV(fpath+"prior2-existence.csv").data
// var waitData = mht.readCSV(fpath+"prior2-logWait.csv").data
var waitData = mht.readCSV(fpath+"prior2-timesper5yr.csv").data

var tjData = mht.readCSV(fpath2+"tj-2-logtimes.csv").data


var df_e = dataFrame(existData, ["val"])
var df_w = dataFrame(waitData, ["val", "logval"])
var df_tj = dataFrame(tjData, ["n_times", "log_times"])

var items = _.uniq(_.pluck(df_e, "item"))
// var items = ["wears socks"]
var genders = _.uniq(_.pluck(df_e, "gender"))

// var prior_samples = 50000
// var prior_burn = prior_samples/2
// var incrOpts = {burn:prior_burn, verbose:false, verboseLag: prior_samples/4}

// var priorModel = function(i){

// 	return IncrementalMH(function(){
		
// 		var itemData_e = subset(df_e, "item", i)
// 		var itemData_w = subset(df_w, "item", i)

// 		foreach(genders, function(g){

// 			var genderData_e = subset(itemData_e, "gender", g)
// 			var genderData_w = subset(itemData_w, "gender", g)

// 			// % of Americans question
// 			var gamma = uniform(0,1)
// 			var delta = uniform(0,50)

// 			var scr = sum(map(function(d){
// 				return betaERP.score([shape_alpha(gamma,delta),
// 										shape_beta(gamma,delta)], avoidEnds(d))
// 			}, _.pluck(genderData_e, "val")))

// 			factor(scr)

// 			var predictiveExistence = beta(shape_alpha(gamma,delta), shape_beta(gamma,delta))

// 			var mu = uniform(-10,10)
// 			var sigma = uniform(0,20)

// 			var scr2 = sum(map(function(d){
// 				return gaussianERP.score([mu, sigma], d)
// 			}, _.pluck(genderData_w, "val")))

// 			factor(scr2)
				
// 			// CHANGE ME
// 			// var discretizedPrior = discretizeLogNormalPrior(predictiveExistence, mu, sigma)

// 			// for communication with habituals.wppl
// 			// query.add(g, discretizedPrior)
// 			query.add(g, [predictiveExistence, mu, sigma])

// 		})					
// 		return query
// 	}, prior_samples, incrOpts)
// }


var questions = ["Q1","Q2"]

var priorModel = function(){

	foreach(items, function(i){

		var itemData_e = subset(df_e, "item", i)
		var itemData_w = subset(df_w, "item", i)

		foreach(questions, function(q){

			if (q=="Q1") {

				// % of Americans question
				// var gamma = uniform(0,1)
				// var delta = uniform(0,50)
				// var scr = sum(map(function(d){
				// 	return betaERP.score([shape_alpha(gamma,delta),
				// 							shape_beta(gamma,delta)], avoidEnds(d))
				// }, _.pluck(itemData_e, "val")))

				var gamma = uniform(0,1)
				var delta = uniform(0,50)

				var mix = uniform(0,1)
				var gamma2 = uniform(0,1)
				var delta2 = uniform(0,50)

				var scr = sum(map(function(d){
					return Math.log(mix*Math.exp(betaERP.score([shape_alpha(gamma,delta),
																shape_beta(gamma,delta)], avoidEnds(d))) +
					(1-mix)*Math.exp(betaERP.score([shape_alpha(gamma2,delta2),
																shape_beta(gamma2,delta2)], avoidEnds(d))))
				}, _.pluck(itemData_e, "val")))


				factor(scr)

				// var predictiveExistence = beta(shape_alpha(gamma,delta), shape_beta(gamma,delta))
				var predictiveExistence = flip(mix) ? beta(shape_alpha(gamma,delta), shape_beta(gamma,delta)) : 
										beta(shape_alpha(gamma2,delta2), shape_beta(gamma2,delta2))


				query.add([i,q], predictiveExistence)

			} else {

				var mu = uniform(0,10)
				var sigma = uniform(0,20)

				var mu2 = uniform(0,10)
				var sigma2 = uniform(0,20)
				var mix = uniform(0,1)

				var scr2 = sum(map(function(d){
					return Math.log(mix*Math.exp(gaussianERP.score([mu, sigma], d)) + 
						(1-mix)*Math.exp(gaussianERP.score([mu2, sigma2], d)))
				}, _.pluck(itemData_w, "logval")))

				factor(scr2)
					
				query.add([i,q], [mix, mu, sigma, mu2, sigma2])

			}
		})

	})			
	return query
}



