// time webppl habituals.wppl --require mht --require tjUtils

var bin_data = mht.readCSV(fpath2+"prior2-discrete_bins.csv").data
var align2afc = {
	"agree-key":"habitual",
	"disagree-key": "mm"
}


var df_bins = _.object(map(function(lst){
	var statebins = _.sortBy(_.values(_.omit(lst, "Item"))) // grab and sort state bins
	var bin_width = statebins[1] - statebins[0] // calculate bin_width based on 1st and 2nd bins (could produce errors if bins are not close to equally spaced)
	return [lst["Item"], 
		{"state_bins": statebins,
		"theta_bins": map(function(x){
			return Math.round(10*(x - (bin_width / 2))) / 10 // get intermediate points (rounded to nearest 0.1)
		},statebins)
		}
		]
}, dataFrame(bin_data, ["0","1","2","3","4","5","6","7","8","9","10"])))


var df_tj_wRounded = map(function(x){
	var i = x["habitual"]
	// var statebins = df_bins[i]["state_bins"]
	var statebins = _.range(-1, 8.5, 0.5)
	// Expt 3 (Figure 3)
	// return _.extend(x, {roundedFreq: nearestPriorBin(x["past_logfreq"], statebins),
	// 					alignedResponse : align2afc[x.response]})
	return _.extend(x, {roundedFreq: nearestPriorBin(x["future_logfreq"], statebins),
						alignedResponse : align2afc[x.response]})
	// Expt 2 (Figure 2)
	// return _.extend(x, {roundedFreq: nearestPriorBin(x["log_times"], statebins),
	// 					alignedResponse : align2afc[x.response]})
}, df_tj)

console.log(df_tj_wRounded )
// console.log(subset(df_tj_wRounded, "habitual", item))
// console.log(df_bins[item])

var prior_samples = 50000
var prior_burn = prior_samples/2
var priorERP = IncrementalMH(priorModel, prior_samples, {burn:prior_burn, verbose:true, verboseLag: prior_burn/5})

var priorERPobject = _.object(map(function(i){
	return [i, _.object(map(function(g){
		return [g, _.object(map(function(q){
			return [q, 	marginalizeERP(priorERP, [i,g,q])]
		},["Q1","Q2"]))]
	}, genders))]
}, items))

// var i = "wears socks"
// var item_bins = df_bins[i]


// var pr_exist = sample(priorERPobject[i]["Q1"]); //exist params
// var pp = sample(priorERPobject[i]["Q2"]); // freq params.

// var prior = mix2GaussiansWithDelta(pr_exist, pp[0], pp[1], pp[2], pp[3], pp[4], item_bins["state_bins"]);
// // prior
// expectation(priorERPobject[i]["Q1"])

// var item_bins = {state_bins: _.range(0, 7, 0.5),
// 				theta_bins: _.range(-0.25,6.75,0.5)}

var item_bins = {
	state_bins: _.range(-1, 8.5, 0.5),
	theta_bins: _.range(-0.75,8.25,0.5)
}

// priorERPobject
// item_bins
var model = function(){

	var speaker_optimality = uniform(0,20)
	var phi = uniform(0,1)

	var prop_male = 0.5
	// var prop_male = uniform(0,1)

	// console.log("so " + speaker_optimality)
	// console.log("phi " + phi)

	foreach(items, function(i){


		// var item_bins = df_bins[i]

		var pr_exist_m = sample(priorERPobject[i]["male"]["Q1"]); //exist params
		var pr_exist_f = sample(priorERPobject[i]["female"]["Q1"]);

		var pp_m = sample(priorERPobject[i]["male"]["Q2"]); // freq params.
		var pp_f = sample(priorERPobject[i]["female"]["Q2"]);

		var prior = mix2GaussiansWithDelta(prop_male, pr_exist_m, pr_exist_f,
											 pp_m[0], pp_m[1], 
											 pp_f[0], pp_f[1], 
											 item_bins["state_bins"]);


		var itemData = subset(df_tj_wRounded, "habitual", i)
		var freqLevels = _.uniq(_.pluck(itemData, "roundedFreq"))

		// console.log("e = " + pr_exist)
		// console.log("pp = " + pp.join(' '))

		foreach(["baseline","preventative","enabling"], function(c){

			var freqData = subset(itemData, "condition", c)
			var responseData = _.pluck(freqData, "alignedResponse")
			var s2 = speaker2(f, prior, speaker_optimality, item_bins["theta_bins"])
			var s2_plusGuess = guessingLink(s2, phi)

			var scr = reduce(function(response, memo) {
							    return memo + s2_plusGuess.score([], response)
								}, 0, responseData)

			// console.log(i + f + scr)
			// console.log("S2 prob = " + Math.exp(s2_plusGuess.score([], "habitual")))
			factor(scr)
			query.add(["predictive", i, f, c], Math.exp(s2_plusGuess.score([], "habitual")))

		})


		// foreach(freqLevels, function(f){

		// 	var freqData = subset(itemData, "roundedFreq", f)
		// 	var grossLevel = freqData[0]["time_period"]
		// 	var responseData = _.pluck(freqData, "alignedResponse")
		// 	var s2 = speaker2(f, prior, speaker_optimality, item_bins["theta_bins"])
		// 	var s2_plusGuess = guessingLink(s2, phi)

		// 	var scr = reduce(function(response, memo) {
		// 					    return memo + s2_plusGuess.score([], response)
		// 						}, 0, responseData)

		// 	// console.log(i + f + scr)
		// 	// console.log("S2 prob = " + Math.exp(s2_plusGuess.score([], "habitual")))
		// 	factor(scr)
		// 	query.add(["predictive", i, f, grossLevel], Math.exp(s2_plusGuess.score([], "habitual")))
		// })


	})

	query.add(["parameter", "global", "speaker_optimality", "NA"], speaker_optimality)
	query.add(["parameter", "global", "phi", "NA"], phi)
	// query.add(["parameter", "global", "prop_male", "NA"], prop_male)
	return query
}

var samples = 1000
var burn = samples/2
var resultsERP = IncrementalMH(model, samples, {verbose: true, verboseLag: samples/20, burn: burn})

// var outputFile = "results/tj2-RSA-log_ntimes-so-phi-IncrMH" + samples/1000 +"k_burn" + burn/1000 +"k_prior-mixGenders0.5-"+ prior_samples/1000 + 
// 	"k_burn" + prior_burn/1000 + "k_discretize-1-8.5-0.5-b.csv"
var outputFile = "results/tj3-RSA-future_log_ntimes-so-phi-IncrMH" + samples/1000 +"k_burn" + burn/1000 +"k_prior-mixGenders0.5-"+ prior_samples/1000 + 
	"k_burn" + prior_burn/1000 + "k_discretize-1-8.5-0.5-a.csv"
var header = "Type,Item,Level,Period,Value"

tjUtils.erpWriter(resultsERP, outputFile, header)
console.log("written to " + outputFile)

