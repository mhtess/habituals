// time webppl habituals.wppl --require mht --require tjUtils

var bin_data = mht.readCSV(fpath2+"prior2-discrete_bins.csv").data
var align2afc = {
	"agree-key":"habitual",
	"disagree-key": "mm"
}


var df_bins = _.object(map(function(lst){
	var statebins = _.sortBy(_.values(_.omit(lst, "Item"))) // grab and sort state bins
	var bin_width = statebins[1] - statebins[0] // calculate bin_width based on 1st and 2nd bins (could produce errors if bins are not close to equally spaced)
	return [lst["Item"], 
		{"state_bins": statebins,
		"theta_bins": map(function(x){
			return Math.round(10*(x - (bin_width / 2))) / 10 // get intermediate points (rounded to nearest 0.1)
		},statebins)
		}
		]
}, dataFrame(bin_data, ["0","1","2","3","4","5","6","7","8","9","10"])))


var df_tj_wRounded = map(function(x){
	var i = x["habitual"]
	// var statebins = df_bins[i]["state_bins"]
	var statebins = _.range(0, 7.5, 0.5)
	return _.extend(x, {roundedFreq: nearestPriorBin(x["log_times"], statebins),
						alignedResponse : align2afc[x.response]})
}, df_tj)

// console.log(subset(df_tj_wRounded, "habitual", item))
// console.log(df_bins[item])

var prior_samples = 100000
var prior_burn = prior_samples/2
var priorERP = IncrementalMH(priorModel, prior_samples, {burn:prior_burn, verbose:true, verboseLag: prior_burn/5})

var priorERPobject = _.object(map(function(i){
	return [i, _.object(map(function(q){
		return [q, 	marginalizeERP(priorERP, [i,q])]
	}, ["Q1","Q2"]))]
}, items))

// var i = "wears socks"
// var item_bins = df_bins[i]


// var pr_exist = sample(priorERPobject[i]["Q1"]); //exist params
// var pp = sample(priorERPobject[i]["Q2"]); // freq params.

// var prior = mix2GaussiansWithDelta(pr_exist, pp[0], pp[1], pp[2], pp[3], pp[4], item_bins["state_bins"]);
// // prior
// expectation(priorERPobject[i]["Q1"])

// var item_bins = {state_bins: _.range(0, 7, 0.5),
// 				theta_bins: _.range(-0.25,6.75,0.5)}

var item_bins = {
	state_bins: _.range(0, 7.5, 0.5),
	theta_bins: _.range(0.25,7.25,0.5)
}

var model = function(){

	var speaker_optimality = uniform(0,20)
	var phi = uniform(0,1)

	// console.log("so " + speaker_optimality)
	// console.log("phi " + phi)

	foreach(items, function(i){


		// var item_bins = df_bins[i]

		var pr_exist = sample(priorERPobject[i]["Q1"]); //exist params
		var pp = sample(priorERPobject[i]["Q2"]); // freq params.

		var prior = mix2GaussiansWithDelta(pr_exist, pp[0], pp[1], pp[2], pp[3], pp[4], item_bins["state_bins"]);
		var itemData = subset(df_tj_wRounded, "habitual", i)
		var freqLevels = _.uniq(_.pluck(itemData, "roundedFreq"))

		// console.log("e = " + pr_exist)
		// console.log("pp = " + pp.join(' '))

		foreach(freqLevels, function(f){

			var freqData = subset(itemData, "roundedFreq", f)
			var grossLevel = freqData[0]["time_period"]
			var responseData = _.pluck(freqData, "alignedResponse")
			var s2 = speaker2(f, prior, speaker_optimality, item_bins["theta_bins"])
			var s2_plusGuess = guessingLink(s2, phi)

			var scr = reduce(function(response, memo) {
							    return memo + s2_plusGuess.score([], response)
								}, 0, responseData)

			// console.log(i + f + scr)
			// console.log("S2 prob = " + Math.exp(s2_plusGuess.score([], "habitual")))
			factor(scr)
			query.add(["predictive", i, f, grossLevel], Math.exp(s2_plusGuess.score([], "habitual")))
		})
	})

	query.add(["parameter", "global", "speaker_optimality", "NA"], speaker_optimality)
	query.add(["parameter", "global", "phi", "NA"], phi)
	return query
}

var samples = 50000
var burn = samples/2
var resultsERP = IncrementalMH(model, samples, {verbose: true, verboseLag: samples/20, burn: burn})

var outputFile = "results/tj2-RSA-log_ntimes-so-phi-IncrMH" + samples/1000 +"k_burn" + burn/1000 +"k_prior-2betas-2lognormals-"+ prior_samples/1000 + 
	"k_burn" + prior_burn/1000 + "k_discretize0-7-0.5-b.csv"

var header = "Type,Item,Level,Period,Value"

tjUtils.erpWriter(resultsERP, outputFile, header)
console.log("written to " + outputFile)